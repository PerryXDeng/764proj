{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f7dbc0-6a4e-489b-8527-3082a3d9133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from chkt_dir/partae/latest.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import functools\n",
    "import numpy as np\n",
    "import mcubes as libmcubes\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from train_gan import Generator, Discriminator, engineer_feature_vec, chairInfo, pca_out, get_part_clusters_for_chairs_iterable, p_percentile_part_count_on_chair, DATA_DIR, centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f3337eb-b42d-4e58-bd7d-70dbe782f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataload.data_utils import loadH5Full\n",
    "import io\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import trimesh\n",
    "\n",
    "colors = [[0, 0, 255, 255],  # blue\n",
    "          [0, 255, 0, 255],  # green\n",
    "          [255, 0, 0, 255],  # red\n",
    "          [255, 255, 0, 255],  # yellow\n",
    "          [0, 255, 255, 255],  # cyan\n",
    "          [255, 0, 255, 255],  # Magenta\n",
    "          [160, 32, 240, 255],  # purple\n",
    "          [255, 255, 240, 255]]  # ivory\n",
    "vox_rez = 64\n",
    "latent_dim=128\n",
    "quadratic_feat=True\n",
    "n_clusters = 8\n",
    "kmfit_ = MiniBatchKMeans(n_clusters=n_clusters,\n",
    "                         random_state=0).fit(pca_out)\n",
    "vec_clusters = kmfit_.labels_\n",
    "\n",
    "maxCountPerCluster = p_percentile_part_count_on_chair(kmfit_, get_part_clusters_for_chairs_iterable(kmfit_), 95).astype(int)\n",
    "clusterEndIndices = maxCountPerCluster.cumsum()\n",
    "clusterStartIndices = clusterEndIndices - maxCountPerCluster\n",
    "count_dim = clusterEndIndices[-1]\n",
    "affine_dim = count_dim*4\n",
    "\n",
    "part_filenames = functools.reduce(lambda l1, l2: l1+l2, map(lambda x:x['filenames'], chairInfo))\n",
    "part_fileorder = np.concatenate(list(map(lambda x:np.arange(0, len(x['filenames'])), chairInfo)))\n",
    "\n",
    "total_num_parts = pca_out.shape[0]\n",
    "pca_dims = pca_out.shape[1]\n",
    "cluster_vec_bools = list(map(lambda cluster:vec_clusters==cluster, range(n_clusters)))\n",
    "cluster_vec_indices = list(map(lambda bools:np.where(bools)[0], cluster_vec_bools))\n",
    "centroids = np.array(list(map(lambda cluster: np.mean(pca_out[cluster_vec_bools[cluster]], axis=0), range(n_clusters))))\n",
    "distances = np.linalg.norm(pca_out - np.repeat(centroids.reshape(-1, n_clusters, pca_dims), total_num_parts, axis=0)[np.arange(total_num_parts), vec_clusters, :], axis=1)\n",
    "distances_by_cluster = list(map(lambda cluster:distances[cluster_vec_bools[cluster]], range(n_clusters)))\n",
    "\n",
    "def sample_from_cluster(cluster_id, strict):\n",
    "    if strict: # choose the closest part index to the cluster\n",
    "        indices = cluster_vec_indices[cluster_id]\n",
    "        return indices[np.argmin(distances_by_cluster[cluster_id])]\n",
    "    return None\n",
    "\n",
    "def sample_dict_from_g(generator, n):\n",
    "    with torch.no_grad():\n",
    "        z = torch.cuda.FloatTensor(np.random.normal(0, 1, (n, latent_dim)))\n",
    "        fake_batch = generator(z)\n",
    "    return fake_batch\n",
    "\n",
    "def score_sample_with_d(discriminator, sample_dict):\n",
    "    with torch.no_grad():\n",
    "        feature_vec = engineer_feature_vec(sample_dict['count'], sample_dict['affine'], quadratic_feat)\n",
    "    return discriminator(feature_vec)\n",
    "\n",
    "def visualize_sample(generator, discriminator):\n",
    "    n = 4\n",
    "    #fig, ax = plt.subplots(1,n, figsize=(16, 4))\n",
    "    sample_dict = sample_dict_from_g(generator, n)\n",
    "    sample_scores = score_sample_with_d(discriminator, sample_dict)\n",
    "    \n",
    "    for (chair_i, (count, affine, score)) in enumerate(zip(sample_dict['count'], sample_dict['affine'], sample_scores)):\n",
    "        count = count.detach().cpu().numpy()\n",
    "        affine = affine.detach().cpu().numpy()\n",
    "        count = count > 0.5\n",
    "        part_indices = []\n",
    "        scales = []\n",
    "        translations = []\n",
    "        categories = []\n",
    "        for (part_i, pred) in enumerate(count):\n",
    "            if pred:\n",
    "                category = np.argmax(clusterEndIndices > part_i)\n",
    "                categories.append(category)\n",
    "                part_indices.append(sample_from_cluster(category, strict=True))\n",
    "                scales.append(affine[part_i*4])\n",
    "                translations.append(affine[part_i*4+1:part_i*4+4] + centroid)\n",
    "        shape_meshes = []\n",
    "        scene = trimesh.Scene()\n",
    "        for (i, scale, tran, latent_category) in zip(part_indices, scales, translations, categories):\n",
    "            part_file = part_filenames[i]\n",
    "            path = os.path.join(DATA_DIR, part_file)\n",
    "            _, voxels, _, _, _, _, _ = loadH5Full(path, resolution=vox_rez)\n",
    "            voxels = voxels[part_fileorder[i]]\n",
    "            vertices, triangles = libmcubes.marching_cubes(voxels, 0)\n",
    "            inCol = colors[latent_category % len(colors)]\n",
    "            mesh = trimesh.Trimesh(vertices, triangles, face_colors=inCol)\n",
    "            mesh.apply_translation((-32, -32, -32))\n",
    "            mesh.apply_scale(scale)\n",
    "            mesh.apply_translation(tran)\n",
    "            scene.add_geometry(mesh)\n",
    "            shape_meshes.append(mesh)\n",
    "        print(count)\n",
    "        print(part_indices)\n",
    "        print(shape_meshes)\n",
    "        shape_meshes = trimesh.util.concatenate(shape_meshes)\n",
    "        shape_meshes.export(os.path.join('data', str(chair_i)+\".obj\"), file_type='obj')\n",
    "        #png = scene.save_image(resolution=[600, 400],visible=True)\n",
    "        #mat = np.array(Image.open(io.BytesIO(data)))\n",
    "        #ax.imshow(mat)\n",
    "        #ax[chair_i].title.set_text(str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ac26d0d-e7f3-4f35-8767-68ae4be67874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "g = Generator(latent_dim, count_dim, affine_dim).cuda()\n",
    "d = Discriminator(count_dim, affine_dim, quadratic_feat).cuda()\n",
    "directory = 'km8_q_6000'\n",
    "g.load_state_dict(torch.load(os.path.join('data', 'weights', directory, 'generator','latest.pth')))\n",
    "d.load_state_dict(torch.load(os.path.join('data', 'weights', directory, 'discriminator','latest.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45d819de-528c-400f-802a-0641b14f966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-49667f3c3c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-e2f3ebc2d074>\u001b[0m in \u001b[0;36mvisualize_sample\u001b[0;34m(generator, discriminator)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_meshes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mshape_meshes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrimesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_meshes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mshape_meshes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchair_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".obj\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'obj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m#png = scene.save_image(resolution=[600, 400],visible=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pqnet/lib/python3.6/site-packages/trimesh/util.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;31m# extract the trimesh type to avoid a circular import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;31m# and assert that both inputs are Trimesh objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m     \u001b[0mtrimesh_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_named\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeshes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trimesh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m     \u001b[0;31m# append faces and vertices of meshes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "visualize_sample(g,d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
